{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8797b85f-44e6-4d7f-a2fe-f129e6424b2b",
   "metadata": {},
   "source": [
    "#### Задача 1 (3 балла). \n",
    "\n",
    "Разовьем тему с бойцами. Напишите игру (можно взять свой старый код в качестве базы), где игроку будет предложено выбрать класс героя: волшебник или боец. Вы должны учесть возможность добавления новых игровых классов (используйте наследование). У волшебника и бойца немного разные атрибуты (можно атрибуты сделать одинаковые в классе-родителе, но разные коэффициенты в классах-детях, на которые они домножаются: например, здоровье волшебника будет 1.0 от стандартного значения, а здоровье бойца - 1.5, а с маной наоборот). Также у них будут разные методы \"нанести удар\" и, если хотите, приветствия. Также у нашего героя, кем бы он ни был, должен быть рюкзак, в котором можно рыться и хранить ограниченный набор вещей (в частности, там хранятся зелья: по умолчанию пусть в начале игры каждому персонажу дается по три зелья). Наконец, нужен класс для противника: можете придумать любого монстра (тоже с возможностью добавления новых монстров, очевидно), с которым герой будет сражаться. Во время сражения неплохо предоставлять игроку выбор вида \"нанести удар - выпить зелье\", а сам урон от удара можно немного рандомизировать с помощью одноименного модуля. Можно еще реализовать и метод sleep для мирного времени, но во время боя он, конечно, не понадобится. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d5d682-790a-482b-aa2a-211341aa0d76",
   "metadata": {},
   "source": [
    "#### Задача 2 (3 балла). \n",
    "\n",
    "Вспомним задачу токенизации. Напишите собственный простенький токенизатор (с самим процессом можно не сильно заморачиваться), который будет создавать генератор с объектами класса Token, у которых будет атрибут text и атрибут category (латинское слово, кириллическое слово или пунктуация). Токенизатор должен быть реализован в классе, у которого должна быть (генераторная) функция tokenize(). Вам понадобится отдельный класс для токенов и re.finditer(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81abb7f0-159a-47bb-bd4c-4411d0aa3fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "class Tokenizer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def tokenize(self):\n",
    "        tokens = re.finditer(r'([А-Яа-я]+)|([A-Za-z]+)|([!\"#$%&()*+,-./:;<=>?@[^_`{}~])', self.data)\n",
    "        for token in tokens:\n",
    "            if token.group(1):\n",
    "                cat = 'ru'\n",
    "                yield Token(token.group(), cat)\n",
    "            elif token.group(2):\n",
    "                cat = 'en'\n",
    "                yield Token(token.group(), cat)\n",
    "            elif token.group(3):\n",
    "                cat = 'punct'\n",
    "                yield Token(token.group(), cat)\n",
    "class Token:\n",
    "    def __init__(self, text, category):\n",
    "        self.text = text\n",
    "        self.category = category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da25139e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вспомним ru\n",
      "задачу ru\n",
      "токенизации ru\n",
      ". punct\n",
      "Напишите ru\n",
      "собственный ru\n",
      "простенький ru\n",
      "токенизатор ru\n",
      "( punct\n",
      "с ru\n",
      "самим ru\n",
      "процессом ru\n",
      "можно ru\n",
      "не ru\n",
      "сильно ru\n",
      "заморачиваться ru\n",
      ") punct\n",
      ", punct\n",
      "который ru\n",
      "будет ru\n",
      "создавать ru\n",
      "генератор ru\n",
      "с ru\n",
      "объектами ru\n",
      "класса ru\n",
      "Token en\n",
      ", punct\n",
      "у ru\n",
      "которых ru\n",
      "будет ru\n",
      "атрибут ru\n",
      "text en\n",
      "и ru\n",
      "атрибут ru\n",
      "category en\n",
      "( punct\n",
      "латинское ru\n",
      "слово ru\n",
      ", punct\n",
      "кириллическое ru\n",
      "слово ru\n",
      "или ru\n",
      "пунктуация ru\n",
      ") punct\n",
      ". punct\n",
      "Токенизатор ru\n",
      "должен ru\n",
      "быть ru\n",
      "реализован ru\n",
      "в ru\n",
      "классе ru\n",
      ", punct\n",
      "у ru\n",
      "которого ru\n",
      "должна ru\n",
      "быть ru\n",
      "( punct\n",
      "генераторная ru\n",
      ") punct\n",
      "функция ru\n",
      "tokenize en\n",
      "( punct\n",
      ") punct\n",
      ". punct\n",
      "Вам ru\n",
      "понадобится ru\n",
      "отдельный ru\n",
      "класс ru\n",
      "для ru\n",
      "токенов ru\n",
      "и ru\n",
      "re en\n",
      ". punct\n",
      "finditer en\n",
      "( punct\n",
      ") punct\n",
      ". punct\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer('Вспомним задачу токенизации. Напишите собственный простенький токенизатор (с самим процессом можно не сильно заморачиваться), который будет создавать генератор с объектами класса Token, у которых будет атрибут text и атрибут category (латинское слово, кириллическое слово или пунктуация). Токенизатор должен быть реализован в классе, у которого должна быть (генераторная) функция tokenize(). Вам понадобится отдельный класс для токенов и re.finditer().')\n",
    "res = t.tokenize()\n",
    "for i in res:\n",
    "    print(i.text, i.category)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
